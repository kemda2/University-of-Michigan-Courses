{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilevel Linear Regression Models\n",
    "**For continuous dependent variables**\n",
    "### Deep dive reading on multilevel linear regression models: West, Welch, and Galecki (2014), *Linear Mixed Models*\n",
    "\n",
    "#### Review: The European Social Survey (ESS) Data\n",
    "* **Data** collected in face to face interviews from national sample of 1703 adults in Belgium.\n",
    "* **Variables:** respondent ID, interviewer ID, 22 variables measuring attitudes and opinions of respondents on various topics. **Interested in interviewer effects on data**\n",
    "* Have final respondent **weights** (based on complex sample design), along with interviewer-specific responce rates (percentage scale): Responce rate of each individual interviewer - an interviewer level covariant.\n",
    "\n",
    "![week-3-img/names-of-multilevel-models.png](week-3-img/names-of-multilevel-models.png)\n",
    "\n",
    "![week-3-img/model-specification.png](week-3-img/model-specification.png)\n",
    "\n",
    "**The B*0* and B*1* do not have the intercept j. They are fixed parameters we are trying to estimate to capture the overall intercept of the model and the overall relationship of x with y.\n",
    "<br>\n",
    "Then we have the predictor x which is measured for each person i in cluster j and then we add these random effects. As in, going above and beyond the standard linear regression model and adding these random effects to capture the between-cluster variance.\n",
    "<br>\n",
    "so u*0j* allows each cluster to have an unique intercept in the model and u*1j* is multiplied by that predictor x1*ij*.\n",
    "<br>\n",
    "This means we can combine u*1j* with B*1* to get the unique slope coefficient for each cluster j.\n",
    "<br>\n",
    "We also have the error term that captures what's not predicted by the regression coefficients and the random effects.**\n",
    "\n",
    "![week-3-img/model-specification.png](week-3-img/fixed-n-random-effects.png)\n",
    "\n",
    "### What distributions do we assume for the u*0j* and u*1j*?\n",
    "* Commonly we assume that these follow normal distribution with a mean of 0 and specified variances and covariances\n",
    "![week-3-img](week-3-img/what-dist-random-effect.png)\n",
    "\n",
    "Since we have 2 random variables here, we assume that these 2 random variables follow a bivariate normal distribution. That's what the N denotes here.\n",
    "* The zero-zero corresponds to the vector of means for those two random effects. We assume that on average, each of those random effects is equal to zero. So, an average cluster looks like we would expect in terms of Beta zero and Beta one\n",
    "* the other matrix which we call d here, that's the variance covariance matrix of these random effects. \n",
    "* So, the variance of the u zero j is Sigma squared zero. The variance of the u one j is Sigma squared one\n",
    "* In addition, we allow those two random effects, the random intercept and the random slope to co-vary, so that Sigma zero one off the diagonal of the d matrix, that's the covariance of those two random effects. So, it could be possible that the higher a random intercept for example, the lower the random slope. That covariance might be negative. That's just one possibility, but we allow for that when specifying this model. \n",
    "* We also assume that the error terms within clusters follow a normal distribution with a mean of zero and a variance of sigma squared. So, you can see we're actually estimating three variants components, Sigma squared, Sigma squared zero, and Sigma squared one, in addition to the covariance of those two random effects Sigma zero one. \n",
    "\n",
    "### We can break the model down to make it simpler.\n",
    "![week-3-img](week-3-img/multilevel-eqn.png)\n",
    "\n",
    "![week-3-img](week-3-img/multilevel-specification.png)\n",
    "\n",
    "![week-3-img](week-3-img/example-multilevel.png)\n",
    "\n",
    "* Let's just take the equation for that random intercept Beta zero j. Initially, we define it by a fixed parameter Beta zero plus that random disturbance u zero j associated with a given cluster. \n",
    "* We fit the model and we compute the estimated variance of the random intercepts. \n",
    "* Let's suppose our estimate of the variability of those u zero j is 2. \n",
    "* Now, we include a fixed effect of subject gender in the model. \n",
    "    * Let's assume we're using a longitudinal study, where j denotes the subjects that are measured repeatedly. \n",
    "    * Gender is something that doesn't change over time. So, notice that when we add male to the model, it has subscript j. \n",
    "        * It doesn't have subscript ij, if i were to denote the time points. \n",
    "        * We also add a fixed effect of that subject-specific covariate Beta two. \n",
    "        * So, we seek to estimate Beta two and in doing this, we're expecting that the variability of those u zero j is actually going to go down, because we're adding a predictor of Beta zero j. \n",
    "    * If that's a good predictor of Beta zero j, male in this case, we expect the variance of those random effects u zero j to go down. Just like we would expect the variance of the random errors to go down in a standard linear regression model by adding predictors. \n",
    "    * Now, after refitting the model with that fixed effect of male in the model, we see that the estimate of Sigma squared zero becomes one. \n",
    "* So, if we compare that to the model that did not include male as a predictor, we can see that we've explained 50 percent of the variability in those intercepts simply by adding the fixed effect of gender to our model. \n",
    "* This is one of the main inferential objectives of multilevel modeling is to see if we can identify predictors at these higher levels, cluster level predictors that can explain variability in these random effects.\n",
    "\n",
    "## Estimating Model Parameters\n",
    "\n",
    "**Computational techniques we will use in Python is:**\n",
    "* **MLE: Maximum Likelihood Estimation.**\n",
    "* **Idea:** What values of model parameters would make the observed data **most likely**?\n",
    "* So we will use Python to compute the MLEs of the fixed effects B*0* and B*1*, B*2* if we added male and it goes on, the variance components (The sigma^2, sigma*0*^2, sigma*1*^2 in addition to standard errors of all the estimated parameters.\n",
    "* MLE are really helpful to find the best estimates for these kinds of regression parameters\n",
    "\n",
    "## Testing the model parametes\n",
    "\n",
    "We can also make inferences about these model parameters using specialized tests for these models.\n",
    "\n",
    "We can calculate the confidence intervals or test hypothesis for model parameters. <br>\n",
    "Specifically, **test Null Hypothesis** that certain parameters are 0 (e.g. a fixed effect is 0 or a variance component is 0 i.e. random effects don't vary) using a technique called **Linelihood ratio testing**\n",
    "\n",
    "**Idea of Likelihood ratio testing:** Does the probability (likelihood) of observed data change substantially if we remove a given parameter (or multiple parameters) from a model? \n",
    "* i.e. We remove certain variance components which means we are removing random effects\n",
    "    * Does that significantly reduce the likelihood of the observed data?\n",
    "    * i.e. are we making the fit of the model worse by removing those components?\n",
    "\n",
    "## ESS Example\n",
    "![week-3-img](week-3-img/ess-eg.png)\n",
    "\n",
    "### Interpretation \n",
    "\n",
    "We use python to compute the MLE of the fixed effet that the overall regression coefficient defining the relationship of Trust In Police **TRSTPLC** with percieved helpfulness and that estimated regression coefficient is positive (0.14) and significant (p < 0.01). <br>\n",
    "So, for a test statistic, we take that (estimated coefficient / std err) and refer that test statistic to a T distribution and we see that the probability of seeing a test statistic that large is very very small. <br>\n",
    "So, the coefficient, the fixed effect in this case is very large relative to the standard error, so we will comclude that this relationship is non 0 and significant. <br>\n",
    "What this implies is that those who have higher levels of trust in police tend to have higher levels of faith in people helping others. <br>\n",
    "That's not all. We go above and beyond the standard regression analysis, in this case, above and beyond the estimation of the regression coefficients. So, in addition to this, we will think of our estimate of our variance.\n",
    "* Let's start with the overall intercept, B*0* in our model, the maximum likelihood of the intercept is 3.89.\n",
    "* Using the same testing approach, we find that this parameter is also significant (p < 0.01)\n",
    "* This implies the mean on our helpfulness scale ranging b/w (0,10) for people with 0 trust in the police is 3.89.\n",
    "\n",
    "With Multilevel models, we go beyond the std regression analysis and we estimate the variability of those random efects.\n",
    "* Estimated variance of the random intercepts: 0.696\n",
    "* estimated variance of random slopes: 0.012\n",
    "* Both are significant based on likelihood ratio tests (significantly greater than 0)\n",
    "    * This means the variability between interviewers is clearly not zero in terms of both the intercepts and the slopes of the model.\n",
    "    * These describe the variance in the u*0j* and u*1j* of our overall model. \n",
    "    * Both of these variance components are non 0\n",
    "**This means: The ESS Interviewers are varying significantly around the overall fixed effects; They have unique intercepts and unique slopes!** <br>\n",
    "They may be collecting higher means and helpfulness in general maybe because of how they are asking questions or because of who they are recruiting but in addition to that they are recording unique slopes implying different interviewers are producing different estimates of the relationship between trust in police and perceived helpfulness.\n",
    "\n",
    "## Model Diagnostics\n",
    "\n",
    "We need to **Examine**  whether our **assumptions** about distributions of random effects and random errors were **reasonable.** <br>\n",
    "Does the **model** seem to **fit well?**\n",
    "\n",
    "1. Look at **distribution of residuals** just like in linear regression.\n",
    "2. Look at distributions of **predicted** values of random interviewer effects, or **EBLUPs;** are there outliers?\n",
    "    * **EBLUP:**  Emppherical Best linear Unbiased Predictor\n",
    "* These are random variables so we can not estimate them directly based on the model but once we fit the model we can calculate the predictions of what those random effects are.\n",
    "* We want to see if there are outliers in terms of particular interviewers.\n",
    "\n",
    "### Residual diagnostics: Normality \n",
    "\n",
    "![week-3-img](week-3-img/residual-diagnostics-normality.png)\n",
    "\n",
    "### Residual diagnostics: Constant Variance \n",
    "\n",
    "**The unique appearance of the scatterplot is because we have only 11 values on the dependent variable of interest**\n",
    "![week-3-img](week-3-img/residual-diagnostics-constand-var.png)\n",
    "\n",
    "### EBLUPs for random intercepts\n",
    "\n",
    "**These are predictions for the random effects for the interviewers that were included in the model.**\n",
    "\n",
    "![week-3-img](week-3-img/eblups-random-intercept.png)\n",
    "\n",
    "* EBLUPs for the random intercepts: We assumed that they were normally distributed with mean zero and constant variance.\n",
    "* This qq plots suggests the same but there is 1 interviewer who pops out.\n",
    "    * We will look at interviewer number 4976 and their data to see why they were so unique\n",
    "\n",
    "### EBLUPs for random slopes\n",
    "\n",
    "![week-3-img](week-3-img/eblups-random-slopes.png)\n",
    "\n",
    "**Slops also seems to be normally distributed. Since one interviewer pops out, we will look at their data as well. **\n",
    "\n",
    "### Looking at the data of the outliers.\n",
    "\n",
    "#### Interviewer 4976: Many responses < 4 for helpfulness!\n",
    "\n",
    "**Unusually large number of responses that are less than 4 for helpfulness**\n",
    "\n",
    "![week-3-img](week-3-img/interviewer-4976.png)\n",
    "\n",
    "* Maybe they were asking the question in a weird way or were leading people to respond about their perceived helpfulness in a different way. Maybe they were making suggestive statements.\n",
    "* But this interviewer is definitely unique in the way they were collecting the measures on the dependent variable and so they had a lower intercept than expected.\n",
    "\n",
    "\n",
    "#### Interviewer 7519: Unique slope caused by missing data!\n",
    "\n",
    "![week-3-img](week-3-img/interviewer-7519.png)\n",
    "\n",
    "**In the ESS study, 88 corosponds to missing data**\n",
    "* When we prepare for this kind of analysis wether it's multilevel or regression modeling, we need to look at descriptive statistics very carefully and make sure that missing data are recoded appropriately to true missing values in the dataset.\n",
    "* So when we did this analysis, the 88 which symbolizes missing data was treated as a real value and the model used that value which caused the interviewers slope to be very flat (as we included that point in the analysis)\n",
    "* That's why they had a lower than expected slope compared to all the other interviewers.\n",
    "* We will need to rerun the analysis after recoding the 88 to a missing data.\n",
    "**This is why descriptive statistics are so important as this interviewer jumped out to be very unique because of just this one datapoint.**\n",
    "\n",
    "## Conclusion\n",
    "* The ESS interviewers are indeed producing unique intercepts and slopes in this overall analysis\n",
    "* The cariance is not necessarily good as it adds uncertainty to estimates of parameters as the interviewers are introducing variability in those estimates.\n",
    "    * We should re-evaluate the variance after removing the outliers \n",
    "* If each interviewer was really working on a random subsample of the full sample, they should be prodicing similar intercepts and slopes assuming our model of interest holds to find that relationship between trust in police and perceived helpfulness.\n",
    "\n",
    "### Next step: in the analysis\n",
    "Add interviewer level covariates to the level 2 equation to explain this variance in the intercepts and slopes.\n",
    "* We could add the interviewer level response rate that's in the dataset\n",
    "* Or if we had measures of interviewer attitudes about these things (helpfulness and trust in police).\n",
    "    * Maybe the interviewer attitudes would explain some of the variability - Maybe it's leading into the way they are asking questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "We wish to fit a multilevel model of the following form to a clustered data set, where students are nested within schools: y = B0 + B1 * X1 + u0 + u1 * X1 + e, where the random effect u0 allows each school to have a unique intercept, and the random effect u1 allows each school to have a unique slope for the student-level predictor X1. Assuming that we allow the random effects to be correlated, how many parameters in total will we be estimating in this model?\n",
    "\n",
    "\n",
    "2\n",
    "\n",
    "\n",
    "4\n",
    "\n",
    "\n",
    "5\n",
    "\n",
    "\n",
    "6\n",
    "\n",
    "Correct \n",
    "Answer: d). We are estimating two fixed effects (B0 and B1), three variance components (the variances of the two random effects, along with their covariance), and the variance of the random errors denoted by e; six parameters in total.\n",
    "\n",
    "# 2\n",
    "You fit a multilevel model of the following form to a clustered data set, where students are nested within schools: y = B0 + B1 * X1 + u1 * X1 + e. Suppose that X1 is the number of hours spent studying for an exam, and y is the exam score (out of 40). You fit the model in Python, and obtain the following output:\n",
    "\n",
    "Coef.-----------------Std.Err------------------z-------------P>|z|--------------[0.025---------0.975] <br>\n",
    "Intercept-------------17.421---------------1.470---------11.848-------------0.000---------14.539\t20.303 <br>\n",
    "hours------------------2.731----------------0.641---------4.257--------------0.000---------1.474\t3.988 <br>\n",
    "hours RE-------------9.609----------------0.112\t <br>\t\t\t\n",
    "\n",
    "What is the correct inference based on the estimates of these parameters and their standard errors?\n",
    "\n",
    "\n",
    "1. Hours has a significant positive relationship with score, and the relationship of hours with score does not vary across schools.\n",
    "\n",
    "\n",
    "2. Hours has a significant positive relationship with score, and the relationship of hours with score varies across schools.\n",
    "\n",
    "    * Correct \n",
    "    * Answer: b). The estimated fixed effect for hours is 2.731 (SE = 0.641), and the p-value for a test of the null hypothesis that this relationship is zero is < 0.001. Hours therefore has a significant positive relationship with test score (as one might expect). The estimated variance of the random hours coefficients across schools is 9.609 (SE = 0.112). The variance component is quite large relative to its standard errors, so we have evidence of significant between-school variance in these relationships as well. Apparently more studying pays off more at some schools than it does at others.\n",
    "\n",
    "\n",
    "\n",
    "3. Hours does not have a significant relationship with score, and the relationship of hours with score does not vary across schools.\n",
    "\n",
    "\n",
    "4. Hours does not have a significant relationship with score, but the relationship of hours with score does vary across schools."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
